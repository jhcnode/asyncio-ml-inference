{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "import msvcrt\n",
    "import sys\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input pipeline ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "dataset_path      = \"dataset10/\"\n",
    "\n",
    "test_labels_file  = \"TestLabel.txt\"\n",
    "train_labels_file = \"TrainLabel.txt\"\n",
    "valid_labels_file = \"ValidLabel.txt\"\n",
    "\n",
    "logs_path\t\t\t= \"logs/\"\n",
    "\n",
    "NUM_DIM=100\n",
    "NUM_LABELS\t\t= 21\n",
    "SEED\t\t\t\t\t= 123\n",
    "TRAIN_BATCH_SIZE\t= 0\n",
    "VALID_BATCH_SIZE\t= 2100\n",
    "TEST_BATCH_SIZE\t\t= 2100\n",
    "TRAIN_MIN_QUEUE_SIZE=  TRAIN_BATCH_SIZE\n",
    "TEST_MIN_QUEUE_SIZE=  TEST_BATCH_SIZE \n",
    "TOTRAL_TRAIN_SIZE=0\n",
    "\n",
    "def encode_label(label):\n",
    "    return int(label)\n",
    "\n",
    "def read_label_file(file):\n",
    "    f = open(file, \"r\")\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    for line in f:\n",
    "        filepath, label = line.split(\" \")\n",
    "        filepaths.append(filepath)\n",
    "        labels.append(encode_label(label))\n",
    "    return filepaths, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# reading labels and file path\n",
    "train_filepaths, train_labels = read_label_file(dataset_path + train_labels_file)\n",
    "valid_filepaths, valid_labels = read_label_file(dataset_path + valid_labels_file)\n",
    "test_filepaths, test_labels = read_label_file(dataset_path + test_labels_file)\n",
    "\n",
    "\n",
    "\n",
    "# transform relative path into full path\n",
    "train_filepaths = [ dataset_path+\"Train/\" + fp for fp in train_filepaths]\n",
    "valid_filepaths = [ dataset_path+\"Valid/\" + fp for fp in valid_filepaths]\n",
    "test_filepaths = [ dataset_path+\"Test/\" + fp for fp in test_filepaths]\n",
    "TOTAL_TRAIN_SIZE=len(train_filepaths)\n",
    "TRAIN_BATCH_SIZE=(int)(TOTAL_TRAIN_SIZE*0.1)\n",
    "\n",
    "\n",
    "# convert string into tensors\n",
    "train_contents = ops.convert_to_tensor(train_filepaths, dtype=dtypes.string)\n",
    "train_labels = tf.one_hot(train_labels,depth=NUM_LABELS,on_value=1,off_value=0,axis=-1)\n",
    "\n",
    "valid_contents = ops.convert_to_tensor(valid_filepaths, dtype=dtypes.string)\n",
    "valid_labels = tf.one_hot(valid_labels,depth=NUM_LABELS,on_value=1,off_value=0,axis=-1)\n",
    "\n",
    "test_contents = ops.convert_to_tensor(test_filepaths, dtype=dtypes.string)\n",
    "test_labels = tf.one_hot(test_labels,depth=NUM_LABELS,on_value=1,off_value=0,axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create input queues\n",
    "train_input_queue = tf.train.slice_input_producer(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[train_contents, train_labels],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True)\n",
    "\n",
    "# create input queues\n",
    "valid_input_queue = tf.train.slice_input_producer(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[valid_contents, valid_labels],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True)\n",
    "\n",
    "test_input_queue = tf.train.slice_input_producer(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[test_contents, test_labels],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True)\n",
    "\n",
    "record_defaults=[]\n",
    "for i in range(NUM_DIM):\n",
    "    record_defaults.append(tf.constant([1], dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "# process path and string tensor into an image and a label\n",
    "file_content = tf.read_file(train_input_queue[0])\n",
    "train_content=  tf.decode_csv(file_content, record_defaults=record_defaults)\n",
    "train_label = train_input_queue[1]\n",
    "\n",
    "file_content = tf.read_file(valid_input_queue[0])\n",
    "valid_content=  tf.decode_csv(file_content, record_defaults=record_defaults)\n",
    "valid_label = valid_input_queue[1]\n",
    "\n",
    "\n",
    "file_content = tf.read_file(test_input_queue[0])\n",
    "test_content=  tf.decode_csv(file_content, record_defaults=record_defaults)  \n",
    "test_label = test_input_queue[1]\n",
    "\n",
    "train_content= tf.stack(train_content)\n",
    "valid_content= tf.stack(valid_content)\n",
    "test_content= tf.stack(test_content)\n",
    "\n",
    "# define tensor shape\n",
    "train_content.set_shape([NUM_DIM])\n",
    "valid_content.set_shape([NUM_DIM])\n",
    "test_content.set_shape([NUM_DIM])\n",
    "\n",
    "\n",
    "# collect batches of images before processing\n",
    "train_content_batch, train_label_batch =  tf.train.batch(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[train_content, train_label],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=TRAIN_BATCH_SIZE\n",
    " \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
    "valid_content_batch, valid_label_batch =  tf.train.batch(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[valid_content, valid_label],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=VALID_BATCH_SIZE\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
    "test_content_batch, test_label_batch =  tf.train.batch(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[test_content, test_label],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=TEST_BATCH_SIZE\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
    "\n",
    "print (\"input pipeline ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def selu(x, name):\n",
    "    with ops.name_scope('elu') as scope:\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x,name))\n",
    "\n",
    "\n",
    "# placeholder is used for feeding data.\n",
    "x = tf.placeholder(tf.float32, shape=[None, NUM_DIM], name = 'x') # none represents variable length of dimension. 784 is the dimension of MNIST data.\n",
    "y_target = tf.placeholder(tf.float32, shape=[None, NUM_LABELS], name = 'y_target') # shape argument is optional, but this is useful to debug.\n",
    "\n",
    "\n",
    "# reshape input data\n",
    "x_data = tf.reshape(x, [-1,NUM_DIM], name=\"x_data\")\n",
    "\n",
    "# Build a fully connected layer\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([NUM_DIM, 1024],stddev=np.sqrt(1/NUM_DIM)), name = 'W_fc1')\n",
    "b_fc1 = tf.Variable(tf.random_normal([1024],stddev=0), name = 'b_fc1')\n",
    "h_fc1 = selu(tf.matmul(x_data, W_fc1) + b_fc1, name=\"h_fc1\")\n",
    "\n",
    "shape = h_fc1.get_shape().as_list()\n",
    "flat_num= shape[1]\n",
    "\n",
    "# Build a fully connected layer\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([flat_num, 512], stddev=np.sqrt(1/flat_num)), name = 'W_fc2')\n",
    "b_fc2 = tf.Variable(tf.random_normal([512],stddev=0), name = 'b_fc2')\n",
    "h_fc2 = selu(tf.matmul(h_fc1, W_fc2) + b_fc2, name=\"h_fc2\")\n",
    "\n",
    "shape = h_fc2.get_shape().as_list()\n",
    "flat_num= shape[1]\n",
    "\n",
    "# Build a fully connected layer\n",
    "W_fc3 = tf.Variable(tf.truncated_normal([flat_num, 256], stddev=np.sqrt(1/flat_num)), name = 'W_fc3')\n",
    "b_fc3 = tf.Variable(tf.random_normal([256],stddev=0), name = 'b_fc3')\n",
    "h_fc3 = selu(tf.matmul(h_fc2, W_fc3) + b_fc3, name=\"h_fc3\")\n",
    "\n",
    "shape = h_fc3.get_shape().as_list()\n",
    "flat_num= shape[1]\n",
    "\n",
    "# Build a fully connected layer\n",
    "W_fc4 = tf.Variable(tf.truncated_normal([flat_num, 128], stddev=np.sqrt(1/flat_num)), name = 'W_fc4')\n",
    "b_fc4 = tf.Variable(tf.random_normal([128],stddev=0), name = 'b_fc4')\n",
    "h_fc4 = selu(tf.matmul(h_fc3, W_fc4) + b_fc4, name=\"h_fc4\")\n",
    "\n",
    "shape = h_fc4.get_shape().as_list()\n",
    "flat_num= shape[1]\n",
    "\n",
    "\n",
    "W_fc5 = tf.Variable(tf.random_normal([flat_num, 64], stddev=np.sqrt(1/flat_num)), name = 'W_fc5')\n",
    "b_fc5 = tf.Variable(tf.random_normal([64],stddev=0), name = 'b_fc5')\n",
    "h_fc5 =selu(tf.matmul(h_fc4, W_fc5) + b_fc5, name=\"h_fc5\")\n",
    "\n",
    "shape = h_fc5.get_shape().as_list()\n",
    "flat_num= shape[1]\n",
    "\n",
    "W_fc6 = tf.Variable(tf.random_normal([flat_num, NUM_LABELS], stddev=np.sqrt(1/flat_num)), name = 'W_fc6')\n",
    "b_fc6 = tf.Variable(tf.random_normal([NUM_LABELS],stddev=0), name = 'b_fc6')\n",
    "\n",
    "\n",
    "pred=tf.matmul(h_fc5, W_fc6) + b_fc6\n",
    "\n",
    "prob_y=tf.nn.softmax(pred, name=\"prob_y\")\n",
    "\n",
    "# define the Loss function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_target))\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "# define optimization algorithm\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y_target, 1))\n",
    "# correct_prediction is list of boolean which is the result of comparing(model prediction , data)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) \n",
    "\n",
    "#save weight\n",
    "t_vars = tf.trainable_variables()\n",
    "saver = tf.train.Saver(max_to_keep=None,var_list=t_vars)\n",
    "saver_def = saver.as_saver_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#config = tf.ConfigProto(log_device_placement=True)\n",
    "#config.gpu_options.per_process_gpu_memory_fraction=0.3 # don't hog all vRAM\n",
    "#config.operation_timeout_in_ms=60000   # terminate on long hangs\n",
    "configure=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True))\n",
    "\n",
    "sess = tf.Session(config=configure) \n",
    "\n",
    "training_loss=tf.summary.scalar('training_loss', cost)\n",
    "validation_loss=tf.summary.scalar('validation_loss', cost)\n",
    "\n",
    "training_accuracy = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
    "validation_accuracy = tf.summary.scalar(\"validation_accuracy\", accuracy)\n",
    "\n",
    "\n",
    "# Merge all summaries into a single op\n",
    "merged_op = tf.summary.merge_all()\n",
    "\n",
    "writer=tf.summary.FileWriter(logs_path, sess.graph)\n",
    "\n",
    "# initialization\n",
    "#init_op = tf.global_variables_initializer()\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session started!\n",
      "Epoch: 0000 cost= 3.234940386\n",
      "INFO:tensorflow:./weight/w-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.0920635 Train-Loss: 3.24278 Validation-Accuracy: 0.0709524 Val-Loss: 3.23323 \n",
      "\n",
      "Epoch: 0001 cost= 2.442936254\n",
      "INFO:tensorflow:./weight/w-1 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.685714 Train-Loss: 1.75428 Validation-Accuracy: 0.7 Val-Loss: 1.73488 \n",
      "\n",
      "Epoch: 0002 cost= 1.409700727\n",
      "INFO:tensorflow:./weight/w-2 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.892063 Train-Loss: 1.08928 Validation-Accuracy: 0.897143 Val-Loss: 1.10173 \n",
      "\n",
      "Epoch: 0003 cost= 0.932139683\n",
      "INFO:tensorflow:./weight/w-3 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.914286 Train-Loss: 0.820767 Validation-Accuracy: 0.940476 Val-Loss: 0.764253 \n",
      "\n",
      "Epoch: 0004 cost= 0.655564302\n",
      "INFO:tensorflow:./weight/w-4 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.965079 Train-Loss: 0.544543 Validation-Accuracy: 0.964286 Val-Loss: 0.551368 \n",
      "\n",
      "Epoch: 0005 cost= 0.482157430\n",
      "INFO:tensorflow:./weight/w-5 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.979365 Train-Loss: 0.401954 Validation-Accuracy: 0.970952 Val-Loss: 0.414056 \n",
      "\n",
      "Epoch: 0006 cost= 0.369102675\n",
      "INFO:tensorflow:./weight/w-6 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.969841 Train-Loss: 0.330041 Validation-Accuracy: 0.974762 Val-Loss: 0.322947 \n",
      "\n",
      "Epoch: 0007 cost= 0.292297408\n",
      "INFO:tensorflow:./weight/w-7 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.973016 Train-Loss: 0.26916 Validation-Accuracy: 0.977143 Val-Loss: 0.261419 \n",
      "\n",
      "Epoch: 0008 cost= 0.239774346\n",
      "INFO:tensorflow:./weight/w-8 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.988889 Train-Loss: 0.196473 Validation-Accuracy: 0.979524 Val-Loss: 0.218255 \n",
      "\n",
      "Epoch: 0009 cost= 0.201765497\n",
      "INFO:tensorflow:./weight/w-9 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.988889 Train-Loss: 0.171135 Validation-Accuracy: 0.979047 Val-Loss: 0.186379 \n",
      "\n",
      "Epoch: 0010 cost= 0.173747241\n",
      "INFO:tensorflow:./weight/w-10 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.988889 Train-Loss: 0.150317 Validation-Accuracy: 0.979524 Val-Loss: 0.162628 \n",
      "\n",
      "Epoch: 0011 cost= 0.152628954\n",
      "INFO:tensorflow:./weight/w-11 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.985714 Train-Loss: 0.142958 Validation-Accuracy: 0.980952 Val-Loss: 0.144167 \n",
      "\n",
      "Epoch: 0012 cost= 0.135985113\n",
      "INFO:tensorflow:./weight/w-12 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.98254 Train-Loss: 0.130346 Validation-Accuracy: 0.982857 Val-Loss: 0.131014 \n",
      "\n",
      "Epoch: 0013 cost= 0.122916918\n",
      "INFO:tensorflow:./weight/w-13 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.987302 Train-Loss: 0.106653 Validation-Accuracy: 0.983333 Val-Loss: 0.118352 \n",
      "\n",
      "Epoch: 0014 cost= 0.111932412\n",
      "INFO:tensorflow:./weight/w-14 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.987302 Train-Loss: 0.105182 Validation-Accuracy: 0.984762 Val-Loss: 0.109119 \n",
      "\n",
      "Epoch: 0015 cost= 0.102644493\n",
      "INFO:tensorflow:./weight/w-15 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.985714 Train-Loss: 0.101093 Validation-Accuracy: 0.984286 Val-Loss: 0.101678 \n",
      "\n",
      "Epoch: 0016 cost= 0.094801544\n",
      "INFO:tensorflow:./weight/w-16 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.988889 Train-Loss: 0.0887934 Validation-Accuracy: 0.985238 Val-Loss: 0.0944812 \n",
      "\n",
      "Epoch: 0017 cost= 0.088303448\n",
      "INFO:tensorflow:./weight/w-17 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.988889 Train-Loss: 0.0779893 Validation-Accuracy: 0.985238 Val-Loss: 0.0889178 \n",
      "\n",
      "Epoch: 0018 cost= 0.082512043\n",
      "INFO:tensorflow:./weight/w-18 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.993651 Train-Loss: 0.069368 Validation-Accuracy: 0.98619 Val-Loss: 0.0835285 \n",
      "\n",
      "Epoch: 0019 cost= 0.077534842\n",
      "INFO:tensorflow:./weight/w-19 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.990476 Train-Loss: 0.0652004 Validation-Accuracy: 0.985714 Val-Loss: 0.0797368 \n",
      "\n",
      "Epoch: 0020 cost= 0.072928359\n",
      "INFO:tensorflow:./weight/w-20 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.987302 Train-Loss: 0.0768311 Validation-Accuracy: 0.988095 Val-Loss: 0.0747801 \n",
      "\n",
      "Epoch: 0021 cost= 0.068943276\n",
      "INFO:tensorflow:./weight/w-21 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0579455 Validation-Accuracy: 0.987619 Val-Loss: 0.0720599 \n",
      "\n",
      "Epoch: 0022 cost= 0.065395301\n",
      "INFO:tensorflow:./weight/w-22 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.992064 Train-Loss: 0.0625816 Validation-Accuracy: 0.988095 Val-Loss: 0.0680327 \n",
      "\n",
      "Epoch: 0023 cost= 0.061966603\n",
      "INFO:tensorflow:./weight/w-23 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.990476 Train-Loss: 0.0609046 Validation-Accuracy: 0.988571 Val-Loss: 0.065611 \n",
      "\n",
      "Epoch: 0024 cost= 0.059072694\n",
      "INFO:tensorflow:./weight/w-24 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.985714 Train-Loss: 0.0534302 Validation-Accuracy: 0.987619 Val-Loss: 0.0635911 \n",
      "\n",
      "Epoch: 0025 cost= 0.056346310\n",
      "INFO:tensorflow:./weight/w-25 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.993651 Train-Loss: 0.0533033 Validation-Accuracy: 0.988571 Val-Loss: 0.0609107 \n",
      "\n",
      "Epoch: 0026 cost= 0.053983708\n",
      "INFO:tensorflow:./weight/w-26 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.992064 Train-Loss: 0.0559823 Validation-Accuracy: 0.988571 Val-Loss: 0.0585238 \n",
      "\n",
      "Epoch: 0027 cost= 0.051730319\n",
      "INFO:tensorflow:./weight/w-27 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.987302 Train-Loss: 0.0702669 Validation-Accuracy: 0.989048 Val-Loss: 0.0576014 \n",
      "\n",
      "Epoch: 0028 cost= 0.050160522\n",
      "INFO:tensorflow:./weight/w-28 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.988889 Train-Loss: 0.0561919 Validation-Accuracy: 0.990476 Val-Loss: 0.0556967 \n",
      "\n",
      "Epoch: 0029 cost= 0.048107903\n",
      "INFO:tensorflow:./weight/w-29 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.993651 Train-Loss: 0.0422309 Validation-Accuracy: 0.989048 Val-Loss: 0.0533444 \n",
      "\n",
      "Epoch: 0030 cost= 0.045966246\n",
      "INFO:tensorflow:./weight/w-30 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.990476 Train-Loss: 0.0581346 Validation-Accuracy: 0.990952 Val-Loss: 0.0523316 \n",
      "\n",
      "Epoch: 0031 cost= 0.044235803\n",
      "INFO:tensorflow:./weight/w-31 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 1.0 Train-Loss: 0.0261372 Validation-Accuracy: 0.99 Val-Loss: 0.0504399 \n",
      "\n",
      "Epoch: 0032 cost= 0.042399029\n",
      "INFO:tensorflow:./weight/w-32 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.988889 Train-Loss: 0.0436985 Validation-Accuracy: 0.990952 Val-Loss: 0.0494838 \n",
      "\n",
      "Epoch: 0033 cost= 0.040810832\n",
      "INFO:tensorflow:./weight/w-33 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.992063 Train-Loss: 0.036073 Validation-Accuracy: 0.989524 Val-Loss: 0.0478864 \n",
      "\n",
      "Epoch: 0034 cost= 0.039465039\n",
      "INFO:tensorflow:./weight/w-34 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0381234 Validation-Accuracy: 0.989524 Val-Loss: 0.0469867 \n",
      "\n",
      "Epoch: 0035 cost= 0.038262118\n",
      "INFO:tensorflow:./weight/w-35 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.993651 Train-Loss: 0.0366514 Validation-Accuracy: 0.99 Val-Loss: 0.0461283 \n",
      "\n",
      "Epoch: 0036 cost= 0.036700261\n",
      "INFO:tensorflow:./weight/w-36 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0307941 Validation-Accuracy: 0.990952 Val-Loss: 0.0448156 \n",
      "\n",
      "Epoch: 0037 cost= 0.036079858\n",
      "INFO:tensorflow:./weight/w-37 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.996825 Train-Loss: 0.0289382 Validation-Accuracy: 0.990476 Val-Loss: 0.0439372 \n",
      "\n",
      "Epoch: 0038 cost= 0.035084260\n",
      "INFO:tensorflow:./weight/w-38 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0406187 Validation-Accuracy: 0.990476 Val-Loss: 0.0438022 \n",
      "\n",
      "Epoch: 0039 cost= 0.033909927\n",
      "INFO:tensorflow:./weight/w-39 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.993651 Train-Loss: 0.0326518 Validation-Accuracy: 0.990952 Val-Loss: 0.0426277 \n",
      "\n",
      "Epoch: 0040 cost= 0.032384523\n",
      "INFO:tensorflow:./weight/w-40 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.993651 Train-Loss: 0.0369602 Validation-Accuracy: 0.989524 Val-Loss: 0.0417135 \n",
      "\n",
      "Epoch: 0041 cost= 0.031490976\n",
      "INFO:tensorflow:./weight/w-41 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.990476 Train-Loss: 0.0414388 Validation-Accuracy: 0.990952 Val-Loss: 0.0407889 \n",
      "\n",
      "Epoch: 0042 cost= 0.030501173\n",
      "INFO:tensorflow:./weight/w-42 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.990476 Train-Loss: 0.0450151 Validation-Accuracy: 0.991428 Val-Loss: 0.0400186 \n",
      "\n",
      "Epoch: 0043 cost= 0.030025806\n",
      "INFO:tensorflow:./weight/w-43 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.993651 Train-Loss: 0.0391486 Validation-Accuracy: 0.991428 Val-Loss: 0.0397564 \n",
      "\n",
      "Epoch: 0044 cost= 0.029212753\n",
      "INFO:tensorflow:./weight/w-44 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0303696 Validation-Accuracy: 0.991428 Val-Loss: 0.0387214 \n",
      "\n",
      "Epoch: 0045 cost= 0.028576573\n",
      "INFO:tensorflow:./weight/w-45 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0225027 Validation-Accuracy: 0.990952 Val-Loss: 0.0383376 \n",
      "\n",
      "Epoch: 0046 cost= 0.027375343\n",
      "INFO:tensorflow:./weight/w-46 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.992064 Train-Loss: 0.0309629 Validation-Accuracy: 0.991905 Val-Loss: 0.0376243 \n",
      "\n",
      "Epoch: 0047 cost= 0.026842205\n",
      "INFO:tensorflow:./weight/w-47 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 1.0 Train-Loss: 0.0150385 Validation-Accuracy: 0.991905 Val-Loss: 0.0374455 \n",
      "\n",
      "Epoch: 0048 cost= 0.025950443\n",
      "INFO:tensorflow:./weight/w-48 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.992064 Train-Loss: 0.040548 Validation-Accuracy: 0.990952 Val-Loss: 0.0364601 \n",
      "\n",
      "Epoch: 0049 cost= 0.025333619\n",
      "INFO:tensorflow:./weight/w-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.998413 Train-Loss: 0.019479 Validation-Accuracy: 0.991905 Val-Loss: 0.0363841 \n",
      "\n",
      "Epoch: 0050 cost= 0.024568936\n",
      "INFO:tensorflow:./weight/w-50 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.029893 Validation-Accuracy: 0.992381 Val-Loss: 0.0356122 \n",
      "\n",
      "Epoch: 0051 cost= 0.023847441\n",
      "INFO:tensorflow:./weight/w-51 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.992064 Train-Loss: 0.0339599 Validation-Accuracy: 0.992381 Val-Loss: 0.035289 \n",
      "\n",
      "Epoch: 0052 cost= 0.023489256\n",
      "INFO:tensorflow:./weight/w-52 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0314724 Validation-Accuracy: 0.991428 Val-Loss: 0.0348403 \n",
      "\n",
      "Epoch: 0053 cost= 0.022680775\n",
      "INFO:tensorflow:./weight/w-53 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0308942 Validation-Accuracy: 0.991905 Val-Loss: 0.0347862 \n",
      "\n",
      "Epoch: 0054 cost= 0.022093212\n",
      "INFO:tensorflow:./weight/w-54 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.996825 Train-Loss: 0.0167836 Validation-Accuracy: 0.991905 Val-Loss: 0.0338483 \n",
      "\n",
      "Epoch: 0055 cost= 0.021655136\n",
      "INFO:tensorflow:./weight/w-55 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.996825 Train-Loss: 0.0182771 Validation-Accuracy: 0.992381 Val-Loss: 0.0336404 \n",
      "\n",
      "Epoch: 0056 cost= 0.021129440\n",
      "INFO:tensorflow:./weight/w-56 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0266313 Validation-Accuracy: 0.991905 Val-Loss: 0.0335738 \n",
      "\n",
      "Epoch: 0057 cost= 0.020748786\n",
      "INFO:tensorflow:./weight/w-57 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.996825 Train-Loss: 0.0150717 Validation-Accuracy: 0.992381 Val-Loss: 0.0330133 \n",
      "\n",
      "Epoch: 0058 cost= 0.020051466\n",
      "INFO:tensorflow:./weight/w-58 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 1.0 Train-Loss: 0.0152773 Validation-Accuracy: 0.991905 Val-Loss: 0.0327889 \n",
      "\n",
      "Epoch: 0059 cost= 0.019753267\n",
      "INFO:tensorflow:./weight/w-59 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0207609 Validation-Accuracy: 0.992381 Val-Loss: 0.0324493 \n",
      "\n",
      "Epoch: 0060 cost= 0.019162143\n",
      "INFO:tensorflow:./weight/w-60 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.993651 Train-Loss: 0.0317648 Validation-Accuracy: 0.992857 Val-Loss: 0.0324914 \n",
      "\n",
      "Epoch: 0061 cost= 0.018853577\n",
      "INFO:tensorflow:./weight/w-61 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 1.0 Train-Loss: 0.0128882 Validation-Accuracy: 0.992381 Val-Loss: 0.0314698 \n",
      "\n",
      "Epoch: 0062 cost= 0.018325155\n",
      "INFO:tensorflow:./weight/w-62 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.998413 Train-Loss: 0.0174261 Validation-Accuracy: 0.993333 Val-Loss: 0.0318613 \n",
      "\n",
      "Epoch: 0063 cost= 0.017966504\n",
      "INFO:tensorflow:./weight/w-63 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.998413 Train-Loss: 0.0161151 Validation-Accuracy: 0.992857 Val-Loss: 0.0310859 \n",
      "\n",
      "Epoch: 0064 cost= 0.017493598\n",
      "INFO:tensorflow:./weight/w-64 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.996825 Train-Loss: 0.0128379 Validation-Accuracy: 0.992857 Val-Loss: 0.0313419 \n",
      "\n",
      "Epoch: 0065 cost= 0.016907177\n",
      "INFO:tensorflow:./weight/w-65 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.992064 Train-Loss: 0.0249961 Validation-Accuracy: 0.993333 Val-Loss: 0.0310243 \n",
      "\n",
      "Epoch: 0066 cost= 0.016608961\n",
      "INFO:tensorflow:./weight/w-66 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.998413 Train-Loss: 0.0124893 Validation-Accuracy: 0.992857 Val-Loss: 0.030278 \n",
      "\n",
      "Epoch: 0067 cost= 0.015961853\n",
      "INFO:tensorflow:./weight/w-67 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.998413 Train-Loss: 0.0102029 Validation-Accuracy: 0.993333 Val-Loss: 0.030248 \n",
      "\n",
      "Epoch: 0068 cost= 0.015635871\n",
      "INFO:tensorflow:./weight/w-68 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.0181116 Validation-Accuracy: 0.992857 Val-Loss: 0.0299429 \n",
      "\n",
      "Epoch: 0069 cost= 0.015326750\n",
      "INFO:tensorflow:./weight/w-69 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.995238 Train-Loss: 0.018917 Validation-Accuracy: 0.992381 Val-Loss: 0.0300246 \n",
      "\n",
      "Epoch: 0070 cost= 0.014935624\n",
      "INFO:tensorflow:./weight/w-70 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Train-Accuracy: 0.993651 Train-Loss: 0.0231986 Validation-Accuracy: 0.993809 Val-Loss: 0.0299202 \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./weight/w-70\n",
      "(result)test accuracy: 0.993809 / weight-70\n",
      "close\n"
     ]
    }
   ],
   "source": [
    "print(\"Session started!\")\n",
    "start_session_time = time.time()\n",
    "sess.run(init_op)\n",
    "\n",
    "# initialize the queue threads to start to shovel data\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "\n",
    "max_epoch=70\n",
    "display_step=1\n",
    "max_accuracy=0\n",
    "max_index=0\n",
    "for epoch in range(0,max_epoch+1):\n",
    "    avg_cost = 0\n",
    "    total_batch=(int)(TOTAL_TRAIN_SIZE/TRAIN_BATCH_SIZE)\n",
    "    for step in range(total_batch):\n",
    "        train_batch=sess.run([tf.cast(train_content_batch, tf.float32),tf.cast(train_label_batch, tf.float32)])\n",
    "        if epoch!=0:\n",
    "            _,c=sess.run([train_step,cost] , feed_dict={x: train_batch[0], y_target: train_batch[1]})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        else:\n",
    "            c=sess.run(cost , feed_dict={x: train_batch[0], y_target: train_batch[1]})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "\n",
    "        print (\"Epoch:\", '%04d' % (epoch), \"cost=\",\"{:.9f}\".format(avg_cost))\n",
    "\n",
    "        valid_batch=sess.run([tf.cast(valid_content_batch, tf.float32),tf.cast(valid_label_batch, tf.float32)])\n",
    "\n",
    "        # traininig accuracy.\n",
    "        train_cos,train_acc, train_summ_acc,train_summ_loss = sess.run(\n",
    "        [cost, accuracy, training_accuracy,training_loss], \n",
    "        feed_dict={x : train_batch[0],  y_target : train_batch[1]})\n",
    "        writer.add_summary(train_summ_acc, epoch) \n",
    "        writer.add_summary(train_summ_loss, epoch) \n",
    "\n",
    "\n",
    "        # validation accuracy.\n",
    "        valid_cos, valid_acc, valid_summ_acc,valid_summ_loss  = sess.run(\n",
    "        [cost,accuracy, validation_accuracy,validation_loss],\n",
    "        feed_dict={x: valid_batch[0], y_target: valid_batch[1]})\n",
    "        writer.add_summary(valid_summ_acc, epoch)\n",
    "        writer.add_summary(valid_summ_loss, epoch)\n",
    "\n",
    "        saver.save(sess,\"./weight/w\",epoch)\n",
    "\n",
    "        print(\"Train-Accuracy:\", train_acc,\"Train-Loss:\", train_cos, \"Validation-Accuracy:\", valid_acc,\"Val-Loss:\", valid_cos,\"\\n\")\n",
    "\n",
    "        if valid_acc>max_accuracy:\n",
    "            max_accuracy=valid_acc\n",
    "            max_index=epoch\n",
    "\n",
    "\n",
    "\n",
    "saver.restore(sess,\"./weight/w-%d\"%(max_index))\n",
    "test_batch=sess.run([tf.cast(test_content_batch,tf.float32),tf.cast(test_label_batch, tf.float32)])\n",
    "max_accuracy=sess.run(accuracy, feed_dict={x: test_batch[0], y_target:  test_batch[1]})\n",
    "\n",
    "print(\"(result)test accuracy: %g / weight-%d\"%(max_accuracy,max_index))    \n",
    "\n",
    "# stop our queue threads and properly close the session\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "writer.close()\n",
    "sess.close()\n",
    "\n",
    "print(\"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
